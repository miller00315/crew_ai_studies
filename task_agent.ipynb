{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQCqAtgxXrmNaynrqo0JN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miller00315/crew_ai_studies/blob/main/task_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6t2pXggtZnFH"
      },
      "outputs": [],
      "source": [
        "#!pip install crewai crewai_tools langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ItXdK8TbZ45k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://aistudio.google.com/apikey\n",
        "\n",
        "https://serper.dev/api-key\n",
        "\n",
        "https://platform.deepseek.com/api_keys\n"
      ],
      "metadata": {
        "id": "eWuagQwGaSbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SERPER_API_KEY\"] = ''\n",
        "os.environ[\"GROQ_API_KEY\"] = ''"
      ],
      "metadata": {
        "id": "miYriiJHaYTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Crew, Task"
      ],
      "metadata": {
        "id": "O9nEbdPGZ40H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(model=\"groq/llama-3.3-70b-versatile\", api_key='')"
      ],
      "metadata": {
        "id": "QaX_aZMEl68x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://console.groq.com/keys"
      ],
      "metadata": {
        "id": "gyBwUkk1lqia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
        "\n",
        "# Initialize the tools\n",
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kew4f-HBZ4yA",
        "outputId": "1eac397d-59d8-4a44-f6e1-5c31ade0d2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator(\"website_url\")\n",
            "/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator(\"website_url\")\n",
            "/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator(\"image_path_url\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent 1: Venue Coordinator\n",
        "venue_coordinator = Agent(\n",
        "    llm=llm,\n",
        "    role=\"Venue Coordinator\",\n",
        "    goal=\"Identify and book an appropriate venue \"\n",
        "    \"based on event requirements\",\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"With a keen sense of space and \"\n",
        "        \"understanding of event logistics, \"\n",
        "        \"you excel at finding and securing \"\n",
        "        \"the perfect venue that fits the event's theme, \"\n",
        "        \"size, and budget constraints.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "EFWvWy30Z4vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Agent 2: Logistics Manager\n",
        "logistics_manager = Agent(\n",
        "    llm=llm,\n",
        "    role='Logistics Manager',\n",
        "    goal=(\n",
        "        \"Manage all logistics for the event \"\n",
        "        \"including catering and equipmen\"\n",
        "    ),\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"Organized and detail-oriented, \"\n",
        "        \"you ensure that every logistical aspect of the event \"\n",
        "        \"from catering to equipment setup \"\n",
        "        \"is flawlessly executed to create a seamless experience.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "gQ5Gt5wyad31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent 3: Marketing and Communications Agent\n",
        "marketing_communications_agent = Agent(\n",
        "    llm=llm,\n",
        "    role=\"Marketing and Communications Agent\",\n",
        "    goal=\"Effectively market the event and \"\n",
        "         \"communicate with participants\",\n",
        "    tools=[search_tool, scrape_tool],\n",
        "    verbose=True,\n",
        "    backstory=(\n",
        "        \"Creative and communicative, \"\n",
        "        \"you craft compelling messages and \"\n",
        "        \"engage with potential attendees \"\n",
        "        \"to maximize event exposure and participation.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "evF-HaNZady0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Venue Pydantic Object**\n",
        "\n",
        "* Create a class VenueDetails using Pydantic BaseModel.\n",
        "\n",
        "* Agents will populate this object with information about different venues by creating different instances of it."
      ],
      "metadata": {
        "id": "RWgXgTudaxin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "# Define a Pydantic model for venue details\n",
        "# (demonstrating Output as Pydantic)\n",
        "class VenueDetails(BaseModel):\n",
        "    name: str\n",
        "    address: str\n",
        "    capacity: int\n",
        "    booking_status: str"
      ],
      "metadata": {
        "id": "2Va97s4HadwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Tasks**\n",
        "* By using output_json, you can specify the structure of the output you want.\n",
        "* By using output_file, you can get your output in a file.\n",
        "* By setting human_input=True, the task will ask for human feedback (whether you like the results or not) before finalising it."
      ],
      "metadata": {
        "id": "XL8IP67Sa_ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "venue_task = Task(\n",
        "    description=\"Find a venue in {event_city} \"\n",
        "                \"that meets criteria for {event_topic}.\",\n",
        "    expected_output=\"All the details of a specifically chosen\"\n",
        "                    \"venue you found to accommodate the event.\",\n",
        "    human_input=True,\n",
        "    output_json=VenueDetails,\n",
        "    output_file=\"venue_details.json\",\n",
        "      # Outputs the venue details as a JSON file\n",
        "    agent=venue_coordinator\n",
        ")"
      ],
      "metadata": {
        "id": "MtGr-FI-adte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistics_task = Task(\n",
        "    description=\"Coordinate catering and \"\n",
        "                 \"equipment for an event \"\n",
        "                 \"with {expected_participants} participants \"\n",
        "                 \"on {tentative_date}.\",\n",
        "    expected_output=\"Confirmation of all logistics arrangements \"\n",
        "                    \"including catering and equipment setup.\",\n",
        "    human_input=True,\n",
        "    agent=logistics_manager\n",
        ")"
      ],
      "metadata": {
        "id": "rSk_aLQ9bpWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marketing_task = Task(\n",
        "    description=\"Promote the {event_topic} \"\n",
        "                \"aiming to engage at least\"\n",
        "                \"{expected_participants} potential attendees.\",\n",
        "    expected_output=\"Report on marketing activities \"\n",
        "                    \"and attendee engagement formatted as markdown.\",\n",
        "    async_execution=True,\n",
        "    output_file=\"marketing_report.md\",  # Outputs the report as a text file\n",
        "    agent=marketing_communications_agent\n",
        ")"
      ],
      "metadata": {
        "id": "auciIbDaadn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the Crew**\n",
        "**Note:** Since you set ```async_execution=True``` for ```logistics_task``` and ```marketing_task tasks```, now the order for them does not matter in the tasks list."
      ],
      "metadata": {
        "id": "L-3Q0YGkbRNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the crew with agents and tasks\n",
        "event_management_crew = Crew(\n",
        "    agents=[venue_coordinator,\n",
        "            logistics_manager,\n",
        "            marketing_communications_agent],\n",
        "\n",
        "    tasks=[venue_task,\n",
        "           logistics_task,\n",
        "           marketing_task],\n",
        "\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "keUcWfyra9Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running the Crew**\n",
        "* Set the inputs for the execution of the crew."
      ],
      "metadata": {
        "id": "bGNM4gnNcIJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_details = {\n",
        "    'event_topic': \"Tech Innovation Conference\",\n",
        "    'event_description': \"A gathering of tech innovators \"\n",
        "                         \"and industry leaders \"\n",
        "                         \"to explore future technologies.\",\n",
        "    'event_city': \"San Francisco\",\n",
        "    'tentative_date': \"2024-09-15\",\n",
        "    'expected_participants': 500,\n",
        "    'budget': 20000,\n",
        "    'venue_type': \"Conference Hall\"\n",
        "}"
      ],
      "metadata": {
        "id": "L3pLKbs4a9VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note 1:** LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video.\n",
        "\n",
        "**Note 2:**\n",
        "* Since you set human_input=True for some tasks, the execution will ask for your input before it finishes running.\n",
        "* When it asks for feedback, use your mouse pointer to first click in the text box before typing anything.\n"
      ],
      "metadata": {
        "id": "YLABCxgicRCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = event_management_crew.kickoff(inputs=event_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "emwr5vEDa9Se",
        "outputId": "e9018879-207a-4967-b584-a3033ea38896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:04][🚀 CREW 'CREW' STARTED, E1CF7E12-4642-4CBF-A133-084D0D1699FC]: 2025-03-11 14:33:04.019614\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:04][📋 TASK STARTED: FIND A VENUE IN SAN FRANCISCO THAT MEETS CRITERIA FOR TECH INNOVATION CONFERENCE.]: 2025-03-11 14:33:04.037062\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:04][🤖 AGENT 'VENUE COORDINATOR' STARTED TASK]: 2025-03-11 14:33:04.038378\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mVenue Coordinator\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mFind a venue in San Francisco that meets criteria for Tech Innovation Conference.\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:04][🤖 LLM CALL STARTED]: 2025-03-11 14:33:04.038638\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:05][✅ LLM CALL COMPLETED]: 2025-03-11 14:33:05.562980\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:05][🤖 TOOL USAGE STARTED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 14:33:05.563780\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:06][✅ TOOL USAGE FINISHED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 14:33:06.315803\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mVenue Coordinator\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"tech conference venues in San Francisco\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'tech conference venues in San Francisco', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Top 12 tech conferences in San Francisco for 2024 - TravelPerk', 'link': 'https://www.travelperk.com/blog/top-tech-conferences-in-san-francisco/', 'snippet': 'With over 200 speakers, the San Francisco Tech Summit offers an action-packed agenda for inspiration, insights, innovation, and connections.', 'position': 1}, {'title': 'Discover Tech Conferences Events & Activities in San Francisco, CA', 'link': 'https://www.eventbrite.com/d/ca--san-francisco/tech-conferences/', 'snippet': 'Tech conferences events in San Francisco, CA ; Tech Weekend | 100 Tech Founders | 50 Venture Capitalists | San Francisco. Thu, Mar 20 • 5:00 PM. Zo House.', 'position': 2}, {'title': 'AI Industry Conference Venue in SF', 'link': 'https://ssfconf.com/ai-conference-venue-sf/', 'snippet': 'The South San Francisco Conference Center is the premier destination for AI summits, expos, and networking events, offering exceptional space, ...', 'position': 3}, {'title': 'Venue - World Agri-Tech Innovation Summit, San Francisco', 'link': 'https://worldagritechusa.com/venue/', 'snippet': 'SUMMIT VENUE: MARRIOTT MARQUIS · San Francisco International Airport (SFO), 14 miles away. Estimated taxi fare: 45 USD (one way) Estimated subway fare: 8.65 USD ...', 'position': 4}, {'title': 'Top 10 Must-Attend Tech Meetups and Conferences in San Francisco', 'link': 'https://www.nucamp.co/blog/coding-bootcamp-san-francisco-ca-top-10-mustattend-tech-meetups-and-conferences-in-san-francisco', 'snippet': 'Some must-attend tech events in San Francisco include the AI Breakthrough sessions, Chief Product Officer Summit, SF #TechWeek, OpenAI Tech Week ...', 'position': 5}, {'title': 'Venue PV CellTech USA - PV Tech Conferences', 'link': 'https://www.pvtechconferences.com/pv-celltech-usa/venue/', 'snippet': 'Enjoy our stunning waterfront venue and easy access to San Francisco International Airport. Settle in to newly transformed accommodations.', 'position': 6}, {'title': 'An Inclusive Dev Conference for Everyone - QCon San Francisco', 'link': 'https://qconsf.com/qcon-cares', 'snippet': 'QCon is working with the Hyatt Regency San Francisco and is committed to providing accessibility for all participants, including those with disabilities or ...', 'position': 7}, {'title': 'Biggest Conferences in San Francisco - Balloon Specialties', 'link': 'https://balloonspecialties.com/2024/09/27/biggest-conferences-in-san-francisco/', 'snippet': '1. TechCrunch Disrupt · 2. AAOS Annual Meeting · 3. JP Morgan Healthcare Conference · 4. DreamForce · 5. Women Impact Tech · 6. Game Developers ...', 'position': 8, 'sitelinks': [{'title': '4. Dreamforce', 'link': 'https://balloonspecialties.com/2024/09/27/biggest-conferences-in-san-francisco/#:~:text=4.%20DreamForce'}, {'title': '6. Game Developers...', 'link': 'https://balloonspecialties.com/2024/09/27/biggest-conferences-in-san-francisco/#:~:text=6.%20Game%20Developers%20Conference%20%28GDC%29'}, {'title': '10. Techspo Silicon Valley', 'link': 'https://balloonspecialties.com/2024/09/27/biggest-conferences-in-san-francisco/#:~:text=10.%20TECHSPO%20Silicon%20Valley'}]}, {'title': 'Top US Tech Conference Cities - Edin Studios', 'link': 'https://edinstudios.com/top-us-tech-conference-cities/', 'snippet': \"San Francisco's tech scene is complemented by numerous meetups, workshops, and seminars happening regularly. Coffee shops become informal networking hubs, and ...\", 'position': 9}, {'title': 'Tech Summit | The Home of Technology', 'link': 'https://techsummit.tech/?srsltid=AfmBOoq97nngKVEOg6nBgjmwVJu8mjSInPedGaoFkpxpw-pEeewbqpxq', 'snippet': 'Power-packed tech excellence with masterclasses, expert speakers, workshops, networking, shows and more. The ultimate events and shows for people in tech!', 'position': 10}], 'peopleAlsoAsk': [{'question': 'What are the top tech conferences in San Francisco?', 'snippet': 'Some must-attend tech events in San Francisco include the AI Breakthrough sessions, Chief Product Officer Summit, SF #TechWeek, OpenAI Tech Week Reception, and Cyber60 Report Launch. These events offer a mix of networking opportunities, hands-on workshops, and sessions with industry leaders.\\nDec 26, 2024', 'title': 'Top 10 Must-Attend Tech Meetups and Conferences in San Francisco', 'link': 'https://www.nucamp.co/blog/coding-bootcamp-san-francisco-ca-top-10-mustattend-tech-meetups-and-conferences-in-san-francisco'}, {'question': 'What is a good tech salary in San Francisco?', 'snippet': 'San Francisco remains a tech job hub with high-paying roles like AI Engineers, Data Scientists, and Cloud Architects. Average salaries range from $120,931 to $200,000. The tech industry in 2022 saw 5.2% growth in SF. Job roles in AI, cloud computing, and cybersecurity are booming.', 'title': 'Ranking the Top 10 High-Paying Tech Jobs in San Francisco in 2024', 'link': 'https://www.nucamp.co/blog/coding-bootcamp-san-francisco-ca-ranking-the-top-10-highpaying-tech-jobs-in-san-francisco-in-2024'}, {'question': 'Where is the Databricks conference in San Francisco?', 'snippet': \"Databricks' commitment to hosting its Data + AI Summit in San Francisco for five more years demonstrates further Bay Area investment. This year's event will take place on June 9-12 in person at Moscone South and West, across more than 50 local San Francisco business venues, and virtually for remote attendees.\", 'title': 'Databricks Deepens San Francisco Investment with New Office and ...', 'link': 'https://www.databricks.com/company/newsroom/press-releases/databricks-deepens-san-francisco-investment-new-office-and-multi'}, {'question': 'What is the name of the tech hub in San Francisco?', 'snippet': 'Silicon Valley is a global center of technological innovation located in the South San Francisco Bay Area of California. The area was named after the primary material found in computer microprocessors. Silicon Valley is home to dozens of major technology, software, and internet companies.', 'title': \"Silicon Valley: Definition, Where It Is, and What It's Famous for\", 'link': 'https://www.investopedia.com/terms/s/siliconvalley.asp'}], 'relatedSearches': [{'query': 'San Francisco tech conferences 2025'}, {'query': 'Best tech conference venues in san francisco'}, {'query': 'Tech conference San Francisco'}, {'query': 'Bay Area tech conferences 2025'}, {'query': 'Upcoming tech conferences in San Francisco'}, {'query': 'Tech conferences in Bay Area'}, {'query': 'Tech conference San Francisco 2024'}, {'query': 'Biggest tech conferences'}], 'credits': 1}\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:06][🤖 LLM CALL STARTED]: 2025-03-11 14:33:06.316310\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:08][✅ LLM CALL COMPLETED]: 2025-03-11 14:33:08.014914\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:08][🤖 TOOL USAGE STARTED: 'READ WEBSITE CONTENT']: 2025-03-11 14:33:08.016352\u001b[00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j606df88epsb1tnas9wsd4v6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 2778, Requested 4128. Please try again in 9.050999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:11][✅ TOOL USAGE FINISHED: 'READ WEBSITE CONTENT']: 2025-03-11 14:33:11.505950\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mVenue Coordinator\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"website_url\\\": \\\"https://ssfconf.com/ai-conference-venue-sf/\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "AI Industry Conference Venue in SF - South San Francisco Conference Center\n",
            "Skip to content\n",
            "Meetings Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Request for Proposal Media Gallery Celebrations Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Ask For A Quote Media Gallery Lodging Bay Area Overview Our Community Attractions Transportation Options Contact General Info Overview Conference Center Authority Rules & Regulations Safe & Secure Events Green Initiative Privacy Policy Blog\n",
            "×\n",
            "Meetings Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Request for Proposal Media Gallery Celebrations Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Ask For A Quote Media Gallery Lodging Bay Area Overview Our Community Attractions Transportation Options Contact General Info Overview Conference Center Authority Rules & Regulations Safe & Secure Events Green Initiative Privacy Policy Blog\n",
            "Meetings Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Request for Proposal Media Gallery Celebrations Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Ask For A Quote Media Gallery Lodging Bay Area Overview Our Community Attractions Transportation Options Contact General Info Overview Conference Center Authority Rules & Regulations Safe & Secure Events Green Initiative Privacy Policy Blog\n",
            "×\n",
            "Meetings Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Request for Proposal Media Gallery Celebrations Overview Promotions / Packages Floor Plans Catering Services Audio/Visual Event Services Ask For A Quote Media Gallery Lodging Bay Area Overview Our Community Attractions Transportation Options Contact General Info Overview Conference Center Authority Rules & Regulations Safe & Secure Events Green Initiative Privacy Policy Blog\n",
            "AI Conference Venue in San Francisco\n",
            "Plan your AI Industry conference, event, expo with us in South San Francisco.\n",
            "Host Your Next AI Industry Conference at the South San Francisco Conference Center\n",
            "The Bay Area Venue for AI Conferences, Expos, and Industry Events\n",
            "Located just minutes from San Francisco International Airport, the South San Francisco Conference Center is the ideal venue for AI industry conferences, expos, and networking events. With its expansive, flexible event spaces, cutting-edge technology infrastructure, and robust security measures, our facility provides a seamless and secure environment for showcasing the latest advancements in artificial intelligence. Whether you're hosting a global summit, an investor forum, or a hands-on AI innovation expo, our venue is designed to accommodate the unique needs of the AI industry while ensuring ease of access for national and international attendees.\n",
            "Explore Floor Plans\n",
            "Call Kathy to Start Planning - 650-877-5205\n",
            "South San Francisco Conference Center is the Perfect AI Conference Venue\n",
            "Expansive, Tech-Ready Event Space Our 20,500+ square feet of flexible event space can be customized for large AI expos, keynote sessions, panel discussions, and hands-on demos. High-speed connectivity and AV support ensure seamless presentations and interactive experiences.\n",
            "Unparalleled Accessibility Just 5 minutes from San Francisco International Airport (SFO) and conveniently located near major highways, hotels, and public transit, getting to and from the conference center is effortless for both domestic and international guests.\n",
            "Secure and Professional Environment AI conferences often involve proprietary research, high-profile speakers, and sensitive discussions. Our venue offers top-tier security services , access control options, and private meeting spaces to ensure a safe and confidential environment for all participants.\n",
            "Book Your AI Conference Today\n",
            "Join the world’s leading AI professionals at the South San Francisco Conference Center. Contact us today to reserve your space and elevate your next AI industry event!\n",
            "Call Kathy to Start Planning - 650-877-5205\n",
            "South San Francisco Conference Center: The Ultimate Destination for AI Conferences\n",
            "The artificial intelligence industry is evolving rapidly, and the need for a state-of-the-art venue to host thought leaders, investors, developers, and technology pioneers has never been greater. The South San Francisco Conference Center is the premier destination for AI summits, expos, and networking events, offering exceptional space, security, and accessibility to ensure a world-class experience.\n",
            "A Space Designed for Innovation and Engagement\n",
            "Our conference center features over 20,500 square feet of configurable space , allowing for large keynote sessions, breakout rooms, hands-on workshops, and networking lounges. The facility is equipped with advanced AV capabilities, high-speed internet, and streaming options , ensuring an optimal experience for in-person and hybrid AI conferences. The flexible room configurations allow for exhibit halls showcasing AI innovations , private investor meetings, and dynamic panel discussions.\n",
            "Unmatched Convenience and Accessibility\n",
            "Situated just five minutes from SFO International Airport , the South San Francisco Conference Center provides effortless access for attendees traveling from around the world. The venue is located near multiple hotels , public transit, and major highways, making it easy for guests to arrive and stay comfortably throughout the duration of the event.\n",
            "Security You Can Trust\n",
            "AI industry events often involve cutting-edge research, confidential discussions, and high-profile attendees. The South San Francisco Conference Center prioritizes security and discretion , offering access control options, private meeting spaces, and on-site security personnel. Organizers can rest assured that their event will be protected, providing a safe and productive environment for all participants.\n",
            "Seamless Event Planning and Support\n",
            "Our dedicated event coordination team is ready to assist with logistics, vendor coordination, and customized event setups to ensure a smooth and successful AI industry gathering. Whether you're hosting a global AI summit, a product launch, or an investor pitch event , the South San Francisco Conference Center is the ultimate venue to bring the future of AI to life .\n",
            "General Info\n",
            "Conference Center Authority\n",
            "Rules & Regulations\n",
            "Green Initiative\n",
            "Privacy Policy\n",
            "Location\n",
            "255 S Airport Blvd. \n",
            "South San Francisco, CA 94080\n",
            "Phone :  (650) 877-8787\n",
            "Map\n",
            "Location\n",
            "South San Francisco Conference Center \n",
            "255 S Airport Blvd. \n",
            "South San Francisco, CA 94080\n",
            "Phone :  (650) 877-8787\n",
            "General Info\n",
            "Conference Center Authority\n",
            "Rules & Regulations\n",
            "Green Initiative\n",
            "Privacy Policy\n",
            "COVID Policy\n",
            "Connect With Us\n",
            "© 2025 South San Francisco Conference Center | Terms & Conditions | Venue Marketing Website by 32° digital\n",
            "Scroll To Top\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:11][🤖 LLM CALL STARTED]: 2025-03-11 14:33:11.506324\u001b[00m\n",
            "\n",
            "\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:11][❌ LLM CALL FAILED: 'LITELLM.RATELIMITERROR: RATELIMITERROR: GROQEXCEPTION - {\"ERROR\":{\"MESSAGE\":\"RATE LIMIT REACHED FOR MODEL `LLAMA-3.3-70B-VERSATILE` IN ORGANIZATION `ORG_01J606DF88EPSB1TNAS9WSD4V6` SERVICE TIER `ON_DEMAND` ON TOKENS PER MINUTE (TPM): LIMIT 6000, USED 2778, REQUESTED 4128. PLEASE TRY AGAIN IN 9.050999999S. NEED MORE TOKENS? UPGRADE TO DEV TIER TODAY AT HTTPS://CONSOLE.GROQ.COM/SETTINGS/BILLING\",\"TYPE\":\"TOKENS\",\"CODE\":\"RATE_LIMIT_EXCEEDED\"}}\n",
            "']: 2025-03-11 14:33:11.694342\u001b[00m\n",
            "\u001b[91m Error during LLM call: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j606df88epsb1tnas9wsd4v6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 2778, Requested 4128. Please try again in 9.050999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
            "\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j606df88epsb1tnas9wsd4v6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 2778, Requested 4128. Please try again in 9.050999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:11][❌ TASK FAILED: FIND A VENUE IN SAN FRANCISCO THAT MEETS CRITERIA FOR TECH INNOVATION CONFERENCE.]: 2025-03-11 14:33:11.698948\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 14:33:11][❌ CREW 'CREW' FAILED, E1CF7E12-4642-4CBF-A133-084D0D1699FC]: 2025-03-11 14:33:11.699052\u001b[00m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j606df88epsb1tnas9wsd4v6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 2778, Requested 4128. Please try again in 9.050999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai_like/chat/handler.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                     response = client.post(\n\u001b[0m\u001b[1;32m    373\u001b[0m                         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOpenAILikeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1549\u001b[0;31m             response = groq_chat_completions.completion(\n\u001b[0m\u001b[1;32m   1550\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/groq/chat/handler.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         return super().completion(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/llms/openai_like/chat/handler.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                     raise OpenAILikeError(\n\u001b[0m\u001b[1;32m    379\u001b[0m                         \u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenAILikeError\u001b[0m: {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j606df88epsb1tnas9wsd4v6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 2778, Requested 4128. Please try again in 9.050999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c716043d4036>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_management_crew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    830\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    302\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    303\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mcrewai_event_bus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskFailedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# Re-raise the exception after emitting the event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mcrewai_event_bus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskStartedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             result = agent.execute_task(\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    263\u001b[0m                     ),\n\u001b[1;32m    264\u001b[0m                 )\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    244\u001b[0m                 ),\n\u001b[1;32m    245\u001b[0m             )\n\u001b[0;32m--> 246\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    247\u001b[0m                 {\n\u001b[1;32m    248\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             self._printer.print(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_context_length_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_context_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             )\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             answer = self.llm.call(\n\u001b[0m\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;31m# --- 2) Make the completion call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 response_message = cast(Choices, cast(ModelResponse, response).choices)[\n\u001b[1;32m    312\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 )  # DO NOT MAKE THREADED - router retry fallback relies on this!\n\u001b[0;32m-> 1154\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"stream\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3068\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   3069\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m429\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                         \u001b[0mexception_mapping_worked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                         raise RateLimitError(\n\u001b[0m\u001b[1;32m    426\u001b[0m                             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"RateLimitError: {exception_provider} - {message}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j606df88epsb1tnas9wsd4v6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 2778, Requested 4128. Please try again in 9.050999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "with open('venue_details.json') as f:\n",
        "   data = json.load(f)\n",
        "\n",
        "pprint(data)"
      ],
      "metadata": {
        "id": "Pku5_80Da9Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JL29cg7cZ2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZVtnirxcZyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcWCpmTGcZv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-vpNQrBcZs0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
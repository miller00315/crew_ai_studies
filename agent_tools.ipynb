{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBQM4Q9EE/UQe0+JHg+1/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miller00315/crew_ai_studies/blob/main/agent_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gzvaCX3iMPVU",
        "outputId": "f07daaa4-b168-491a-e9d7-015c573aa0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-0.105.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting crewai_tools\n",
            "  Downloading crewai_tools-0.37.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.1.8)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.7.3-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.39.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json5>=0.10.0 (from crewai)\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.60.2 (from crewai)\n",
            "  Downloading litellm-1.60.2-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.61.1)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Collecting opentelemetry-api>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.10.6)\n",
            "Collecting python-dotenv>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.11.13)\n",
            "Collecting httpx<0.28.0,>=0.23.0 (from litellm==1.60.2->crewai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (4.23.0)\n",
            "Collecting tiktoken>=0.7.0 (from litellm==1.60.2->crewai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (0.21.0)\n",
            "Collecting docker>=7.1.0 (from crewai_tools)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain>=0.1.114 (from crewai_tools)\n",
            "  Downloading embedchain-0.1.127-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai_tools)\n",
            "  Downloading lancedb-0.21.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting pyright>=1.1.350 (from crewai_tools)\n",
            "  Downloading pyright-1.1.396-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai_tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools) (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.41)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.11)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.18.3)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Requirement already satisfied: urllib3>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.3.0)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading posthog-3.19.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (4.13.3)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (1.79.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langsmith<0.4,>=0.1.125 (from langchain_community)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.54 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading mem0ai-0.1.67-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm==1.60.2->crewai)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tokenizers (from litellm==1.60.2->crewai)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Requirement already satisfied: jiter<0.9,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.8.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.27.2)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai_tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai_tools) (18.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai_tools) (24.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.18)\n",
            "Collecting importlib-metadata>=6.8.0 (from litellm==1.60.2->crewai)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (1.69.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber>=0.11.4->crewai) (3.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai_tools)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai_tools) (2.6)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading types_requests-2.32.0.20250306-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.17.2)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.5.23->crewai)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.24.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.26.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (3.29.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.14.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.0.7)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai_tools) (5.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm==1.60.2->crewai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm==1.60.2->crewai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.60.2->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.60.2->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.23.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (0.9.0)\n",
            "Collecting psycopg2-binary<3.0.0,>=2.9.10 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pytz<2025.0,>=2024.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading qdrant_client-1.13.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.60.2->crewai) (0.28.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (14.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.4.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (0.14.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (2024.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (2025.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.3.0)\n",
            "Collecting grpcio>=1.58.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools) (0.6.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (4.1.0)\n",
            "Downloading crewai-0.105.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.1/252.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.60.2-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.37.0-py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.5/548.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.8.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.127-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading instructor-1.7.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.39.1-py3-none-any.whl (20 kB)\n",
            "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading lancedb-0.21.0-cp39-abi3-manylinux_2_28_x86_64.whl (33.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading pyright-1.1.396-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading cohere-5.14.0-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.67-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.19.1-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.13.3-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250306-py3-none-any.whl (20 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=a06700dccc6f9c535f7ba92c5aa278b2cd1dc087459463c84f481d1637dbff69\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: schema, pytz, pypika, monotonic, durationpy, appdirs, uvloop, uvicorn, uv, types-requests, tomli-w, tomli, pytube, python-dotenv, pysbd, pyproject_hooks, pypdfium2, pypdf, psycopg2-binary, protobuf, portalocker, overrides, opentelemetry-util-http, nodeenv, mypy-extensions, mmh3, marshmallow, Mako, jsonref, json5, json-repair, jedi, importlib-metadata, humanfriendly, httpx-sse, httptools, grpcio, fastavro, deprecation, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, pyright, posthog, opentelemetry-proto, opentelemetry-api, httpx, grpcio-tools, gptcache, docker, coloredlogs, build, alembic, tokenizers, pyvis, pydantic-settings, pdfminer.six, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, langsmith, lancedb, kubernetes, fastapi, dataclasses-json, auth0-python, qdrant-client, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, litellm, instructor, cohere, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-openai, opentelemetry-instrumentation-fastapi, langchain_community, chromadb, langchain-experimental, crewai, langchain-cohere, embedchain, crewai_tools\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.70.0\n",
            "    Uninstalling grpcio-1.70.0:\n",
            "      Successfully uninstalled grpcio-1.70.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.11\n",
            "    Uninstalling langsmith-0.3.11:\n",
            "      Successfully uninstalled langsmith-0.3.11\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
            "google-genai 1.4.0 requires httpx<1.0.0dev,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 alembic-1.15.1 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 cohere-5.14.0 coloredlogs-15.0.1 crewai-0.105.0 crewai_tools-0.37.0 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 durationpy-0.9 embedchain-0.1.127 fastapi-0.115.11 fastavro-1.10.0 gptcache-0.1.44 grpcio-1.71.0 grpcio-tools-1.71.0 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.5.0 instructor-1.7.3 jedi-0.19.2 json-repair-0.39.1 json5-0.10.0 jsonref-1.1.0 kubernetes-32.0.1 lancedb-0.21.0 langchain-cohere-0.3.5 langchain-experimental-0.3.4 langchain-openai-0.2.14 langchain_community-0.3.19 langsmith-0.1.147 litellm-1.60.2 marshmallow-3.26.1 mem0ai-0.1.67 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.0.0 nodeenv-1.9.1 onnxruntime-1.21.0 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-exporter-otlp-proto-http-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 pdfminer.six-20231228 pdfplumber-0.11.5 portalocker-2.10.1 posthog-3.19.1 protobuf-5.29.3 psycopg2-binary-2.9.10 pydantic-settings-2.8.1 pypdf-5.3.1 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.396 pysbd-0.3.4 python-dotenv-1.0.1 pytube-15.0.0 pytz-2024.2 pyvis-0.3.2 qdrant-client-1.13.3 schema-0.7.7 starlette-0.46.1 tiktoken-0.7.0 tokenizers-0.20.3 tomli-2.2.1 tomli-w-1.2.0 types-requests-2.32.0.20250306 typing-inspect-0.9.0 uv-0.6.5 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "ea50eca1cb3945a792d2d022e93038d2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install crewai crewai_tools langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "b-Gj382HNlP3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SERPER_API_KEY\"] = ''"
      ],
      "metadata": {
        "id": "aaJttCO1OxQf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "import os\n",
        "\n",
        "google_llm = LLM(\n",
        "              model='gemini/gemini-1.5-flash',\n",
        "              api_key='')"
      ],
      "metadata": {
        "id": "74WoSE3pNlMz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import DirectoryReadTool, \\\n",
        "                         FileReadTool, \\\n",
        "                         SerperDevTool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZPEz7oeNlKB",
        "outputId": "57626ed1-c423-4834-ce0b-87f804037020"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator(\"website_url\")\n",
            "/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator(\"website_url\")\n",
            "/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  @validator(\"image_path_url\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_read_tool = DirectoryReadTool(directory='./instructions')\n",
        "file_read_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()"
      ],
      "metadata": {
        "id": "RXSK5ZRdNlHj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew"
      ],
      "metadata": {
        "id": "1Eqd7y6IPBWm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_rep_agent = Agent(\n",
        "    llm=google_llm,\n",
        "    role=\"Sales Representative\",\n",
        "    goal=\"Identify high-value leads that match \"\n",
        "         \"our ideal customer profile\",\n",
        "    backstory=(\n",
        "        \"As a part of the dynamic sales team at CrewAI, \"\n",
        "        \"your mission is to scour \"\n",
        "        \"the digital landscape for potential leads. \"\n",
        "        \"Armed with cutting-edge tools \"\n",
        "        \"and a strategic mindset, you analyze data, \"\n",
        "        \"trends, and interactions to \"\n",
        "        \"unearth opportunities that others might overlook. \"\n",
        "        \"Your work is crucial in paving the way \"\n",
        "        \"for meaningful engagements and driving the company's growth.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "Uwmbrps9NlFB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lead_sales_rep_agent = Agent(\n",
        "    llm=google_llm,\n",
        "    role=\"Lead Sales Representative\",\n",
        "    goal=\"Nurture leads with personalized, compelling communications\",\n",
        "    backstory=(\n",
        "        \"Within the vibrant ecosystem of CrewAI's sales department, \"\n",
        "        \"you stand out as the bridge between potential clients \"\n",
        "        \"and the solutions they need.\"\n",
        "        \"By creating engaging, personalized messages, \"\n",
        "        \"you not only inform leads about our offerings \"\n",
        "        \"but also make them feel seen and heard.\"\n",
        "        \"Your role is pivotal in converting interest \"\n",
        "        \"into action, guiding leads through the journey \"\n",
        "        \"from curiosity to commitment.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "CteEcuGeNlCP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import BaseTool"
      ],
      "metadata": {
        "id": "7gooidWBQDaA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysisTool(BaseTool):\n",
        "    name: str =\"Sentiment Analysis Tool\"\n",
        "    description: str = (\"Analyzes the sentiment of text \"\n",
        "         \"to ensure positive and engaging communication.\")\n",
        "\n",
        "    def _run(self, text: str) -> str:\n",
        "        # Your custom code tool goes here\n",
        "        return \"positive\""
      ],
      "metadata": {
        "id": "F3XEacdkQDXc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analysis_tool = SentimentAnalysisTool()"
      ],
      "metadata": {
        "id": "zR_khzxJQDQJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lead_profiling_task = Task(\n",
        "    description=(\n",
        "        \"Conduct an in-depth analysis of {lead_name}, \"\n",
        "        \"a company in the {industry} sector \"\n",
        "        \"that recently showed interest in our solutions. \"\n",
        "        \"Utilize all available data sources \"\n",
        "        \"to compile a detailed profile, \"\n",
        "        \"focusing on key decision-makers, recent business \"\n",
        "        \"developments, and potential needs \"\n",
        "        \"that align with our offerings. \"\n",
        "        \"This task is crucial for tailoring \"\n",
        "        \"our engagement strategy effectively.\\n\"\n",
        "        \"Don't make assumptions and \"\n",
        "        \"only use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive report on {lead_name}, \"\n",
        "        \"including company background, \"\n",
        "        \"key personnel, recent milestones, and identified needs. \"\n",
        "        \"Highlight potential areas where \"\n",
        "        \"our solutions can provide value, \"\n",
        "        \"and suggest personalized engagement strategies.\"\n",
        "    ),\n",
        "    tools=[directory_read_tool, file_read_tool, search_tool],\n",
        "    agent=sales_rep_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "iJ0POYf0QDNe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personalized_outreach_task = Task(\n",
        "    description=(\n",
        "        \"Using the insights gathered from \"\n",
        "        \"the lead profiling report on {lead_name}, \"\n",
        "        \"craft a personalized outreach campaign \"\n",
        "        \"aimed at {key_decision_maker}, \"\n",
        "        \"the {position} of {lead_name}. \"\n",
        "        \"The campaign should address their recent {milestone} \"\n",
        "        \"and how our solutions can support their goals. \"\n",
        "        \"Your communication must resonate \"\n",
        "        \"with {lead_name}'s company culture and values, \"\n",
        "        \"demonstrating a deep understanding of \"\n",
        "        \"their business and needs.\\n\"\n",
        "        \"Don't make assumptions and only \"\n",
        "        \"use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A series of personalized email drafts \"\n",
        "        \"tailored to {lead_name}, \"\n",
        "        \"specifically targeting {key_decision_maker}.\"\n",
        "        \"Each draft should include \"\n",
        "        \"a compelling narrative that connects our solutions \"\n",
        "        \"with their recent achievements and future goals. \"\n",
        "        \"Ensure the tone is engaging, professional, \"\n",
        "        \"and aligned with {lead_name}'s corporate identity.\"\n",
        "    ),\n",
        "    tools=[sentiment_analysis_tool, search_tool],\n",
        "    agent=lead_sales_rep_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "zKeqobutQDK1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[sales_rep_agent,\n",
        "            lead_sales_rep_agent],\n",
        "  tasks=[lead_profiling_task,\n",
        "           personalized_outreach_task],\n",
        "  verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "ER4WFHLfQbQK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"lead_name\": \"DeepLearningAI\",\n",
        "    \"industry\": \"Online Learning Platform\",\n",
        "    \"key_decision_maker\": \"Andrew Ng\",\n",
        "    \"position\": \"CEO\",\n",
        "    \"milestone\": \"product launch\"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcdHU38BQkxx",
        "outputId": "5a1b5852-05d3-49f2-db43-ebbe3889e2a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:45][🚀 CREW 'CREW' STARTED, 92697830-FA5C-4BBF-A230-8261F42C8F0A]: 2025-03-11 12:56:45.617872\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:45][📋 TASK STARTED: CONDUCT AN IN-DEPTH ANALYSIS OF DEEPLEARNINGAI, A COMPANY IN THE ONLINE LEARNING PLATFORM SECTOR THAT RECENTLY SHOWED INTEREST IN OUR SOLUTIONS. UTILIZE ALL AVAILABLE DATA SOURCES TO COMPILE A DETAILED PROFILE, FOCUSING ON KEY DECISION-MAKERS, RECENT BUSINESS DEVELOPMENTS, AND POTENTIAL NEEDS THAT ALIGN WITH OUR OFFERINGS. THIS TASK IS CRUCIAL FOR TAILORING OUR ENGAGEMENT STRATEGY EFFECTIVELY.\n",
            "DON'T MAKE ASSUMPTIONS AND ONLY USE INFORMATION YOU ABSOLUTELY SURE ABOUT.]: 2025-03-11 12:56:45.638180\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:45][🤖 AGENT 'SALES REPRESENTATIVE' STARTED TASK]: 2025-03-11 12:56:45.640129\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSales Representative\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mConduct an in-depth analysis of DeepLearningAI, a company in the Online Learning Platform sector that recently showed interest in our solutions. Utilize all available data sources to compile a detailed profile, focusing on key decision-makers, recent business developments, and potential needs that align with our offerings. This task is crucial for tailoring our engagement strategy effectively.\n",
            "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:45][🤖 LLM CALL STARTED]: 2025-03-11 12:56:45.640478\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:52][✅ LLM CALL COMPLETED]: 2025-03-11 12:56:52.156172\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:52][🤖 TOOL USAGE STARTED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:56:52.157375\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:52][✅ TOOL USAGE FINISHED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:56:52.755778\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSales Representative\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"DeepLearningAI\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'DeepLearningAI', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'DeepLearning.AI: Start or Advance Your Career in AI', 'link': 'https://www.deeplearning.ai/', 'snippet': 'Join over 7 million people learning how to use and build AI. AI Courses and Specializations. Build a foundation of machine learning and AI skills.', 'position': 1, 'sitelinks': [{'title': 'Courses', 'link': 'https://www.deeplearning.ai/courses/'}, {'title': 'About', 'link': 'https://www.deeplearning.ai/about/'}, {'title': 'ChatGPT Prompt Engineering', 'link': 'https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/'}, {'title': 'Generative AI for Everyone', 'link': 'https://www.deeplearning.ai/courses/generative-ai-for-everyone/'}, {'title': 'Learning Platform', 'link': 'https://learn.deeplearning.ai/'}]}, {'title': 'DeepLearningAI - YouTube', 'link': 'https://www.youtube.com/c/deeplearningai', 'snippet': 'The official DeepLearning.AI YouTube channel! Here you can find the videos from our Coursera programs on machine learning as well as recorded events.', 'position': 2}, {'title': 'DeepLearning.AI Online Courses - Coursera', 'link': 'https://www.coursera.org/partners/deeplearning-ai', 'snippet': 'Learn to build AI apps with Tensorflow. Build, train, and optimize deep neural networks and dive deep into Computer Vision, Natural Language Processing, and ...', 'position': 3}, {'title': 'DeepLearning.AI - LinkedIn', 'link': 'https://www.linkedin.com/company/deeplearningai', 'snippet': 'DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.', 'position': 4}, {'title': 'Deep Learning Specialization - Coursera', 'link': 'https://www.coursera.org/specializations/deep-learning', 'snippet': 'Become a Machine Learning expert. Master the fundamentals of deep learning and break into AI. Recently updated with cutting-edge techniques!', 'position': 5}, {'title': 'DeepLearning.AI (@deeplearningai) • Instagram photos and videos', 'link': 'https://www.instagram.com/deeplearningai/?hl=en', 'snippet': 'We are an education technology company with the mission to grow and connect the global AI community. · Photo by DeepLearning.AI on March 10, 2025.', 'position': 6}, {'title': 'DeepLearning.AI Courses - YouTube', 'link': 'https://www.youtube.com/playlist?list=PLkDaE6sCZn6Fowk0hfL5O5uZWWQegaQz5', 'snippet': 'DeepLearning.AI Courses · New course! · Learn how to evaluate AI agents in this new course with Arize AI! · New course with StatQuest with Josh Starmer! · New ...', 'position': 7}], 'peopleAlsoAsk': [{'question': 'What does DeepLearning.AI do?', 'snippet': 'DeepLearning.AI has created high-quality AI programs on Coursera that have gained an extensive global following. By providing a platform for education and fostering a tight-knit community, DeepLearning.AI has become the pathway for anyone looking to build an AI career.', 'title': 'About - DeepLearning.AI', 'link': 'https://www.deeplearning.ai/about/'}, {'question': 'Who is the CEO of deep learning company?', 'snippet': 'A globally recognized leader in AI, Dr. Andrew Ng leads AI Fund as the Managing General Partner. Additionally, he is the Founder and CEO of Landing AI, founder of DeepLearning.AI, chairman and co-founder of Coursera, and an adjunct professor at Stanford University.', 'title': 'Andrew Ng - AI FUND', 'link': 'https://aifund.ai/team-member/andrew-ng/'}, {'question': 'What is deep learning in simple words?', 'snippet': 'Deep learning is a type of machine learning that uses artificial neural networks to learn from data. Artificial neural networks are inspired by the human brain, and they can be used to solve a wide variety of problems, including image recognition, natural language processing, and speech recognition.', 'title': 'What is Deep Learning? Applications & Examples | Google Cloud', 'link': 'https://cloud.google.com/discover/what-is-deep-learning'}, {'question': 'Does DeepLearning.AI give certificates?', 'snippet': 'TensorFlow is one of the most in-demand and popular open-source deep learning frameworks available today. The DeepLearning.AI TensorFlow Developer Professional Certificate program teaches you applied machine learning skills with TensorFlow so you can build and train powerful models.', 'title': 'DeepLearning.AI TensorFlow Developer Professional Certificate', 'link': 'https://www.coursera.org/professional-certificates/tensorflow-in-practice'}], 'relatedSearches': [{'query': 'deeplearning.ai login'}, {'query': 'deeplearning.ai courses'}, {'query': 'deeplearning.ai courses free'}, {'query': 'Deep learning AI Andrew Ng'}, {'query': 'deeplearning.ai coursera'}, {'query': 'Deep Learning course free'}, {'query': 'Deep learning AI prompt engineering'}, {'query': 'deeplearning.ai certificate'}], 'credits': 1}\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:56:52][🤖 LLM CALL STARTED]: 2025-03-11 12:56:52.756856\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:00][✅ LLM CALL COMPLETED]: 2025-03-11 12:57:00.371655\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:00][🤖 TOOL USAGE STARTED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:57:00.373570\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:01][✅ TOOL USAGE FINISHED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:57:01.110581\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSales Representative\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I have gathered some information about DeepLearning.AI from the web search.  I found information about their courses, their founder Andrew Ng, and their presence on various platforms like Coursera, YouTube, and LinkedIn.  To get a more complete picture, I should look for more specific information on their business development and key decision-makers.  I will refine my search query to find more detailed information.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"DeepLearningAI business development key personnel\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'DeepLearningAI business development key personnel', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'DeepLearning.AI: Start or Advance Your Career in AI', 'link': 'https://www.deeplearning.ai/', 'snippet': 'Join over 7 million people learning how to use and build AI. AI Courses and Specializations. Build a foundation of machine learning and AI skills.', 'position': 1, 'sitelinks': [{'title': 'Careers', 'link': 'https://www.deeplearning.ai/careers/'}, {'title': 'Courses', 'link': 'https://www.deeplearning.ai/courses/'}, {'title': 'DeepLearning.AI', 'link': 'https://community.deeplearning.ai/'}, {'title': 'AI Dev 25', 'link': 'https://ai-dev.deeplearning.ai/'}]}, {'title': 'DeepLearning.AI - LinkedIn', 'link': 'https://www.linkedin.com/company/deeplearningai', 'snippet': 'Learn the skills to start or advance your AI career. World-class education. Hands-on training. Collaborative community of peers and mentors.', 'position': 2}, {'title': 'Sign In - Multi AI Agent Systems with crewAI - DeepLearning.AI', 'link': 'https://learn.deeplearning.ai/courses/multi-ai-agent-systems-with-crewai/lesson/9/tools-for-a-customer-outreach-campaign-(code)', 'snippet': 'Automate business workflows with multi-AI agent systems. Exceed the performance of prompting a single LLM by designing and prompting a team of AI agents ...', 'position': 3}, {'title': 'Andrew Ng - Founder - DeepLearning.AI - LinkedIn', 'link': 'https://www.linkedin.com/in/andrewyng', 'snippet': 'Andrew Ng is an influencer. Founder of DeepLearning.AI; Managing General Partner of AI Fund; Exec Chairman of Landing AI.', 'position': 4}, {'title': 'Courses - DeepLearning.AI', 'link': 'https://www.deeplearning.ai/courses/', 'snippet': 'Grow your AI career with foundational specializations and skill-specific short courses taught by leaders in the field.', 'position': 5, 'sitelinks': [{'title': 'AI Python for Beginners', 'link': 'https://www.deeplearning.ai/short-courses/ai-python-for-beginners/'}, {'title': 'AI for Everyone', 'link': 'https://www.deeplearning.ai/courses/ai-for-everyone/'}, {'title': 'Generative AI for Everyone', 'link': 'https://www.deeplearning.ai/courses/generative-ai-for-everyone/'}, {'title': 'The Batch', 'link': 'https://www.deeplearning.ai/the-batch/'}]}, {'title': 'Looking to better understand AI Agents - DeepLearning.AI', 'link': 'https://community.deeplearning.ai/t/looking-to-better-understand-ai-agents/635115', 'snippet': 'We created AI agents to perform financial analysis. We created a data analyst agent that had this back story: backstory=\"Specializing in financial markets.', 'position': 6}, {'title': 'deeplearning.ai Information - RocketReach', 'link': 'https://rocketreach.co/deeplearningai-profile_b4556bbefc954d11', 'snippet': 'Top deeplearning.ai Employees ; Erwin Huizenga. Course Instructor at deeplearning.ai. Singapore ; Alice Lin. Director of Marketing and Communications at ...', 'position': 7}, {'title': 'AI learning Path for Consultants and Managers - AI For Everyone', 'link': 'https://community.deeplearning.ai/t/ai-learning-path-for-consultants-and-managers/311300', 'snippet': 'The course covers basic AI concepts such as machine learning, deep learning, and neural networks, as well as their use cases and applications.', 'position': 8}, {'title': 'DeepLearning.AI Online Courses - Coursera', 'link': 'https://www.coursera.org/partners/deeplearning-ai', 'snippet': 'Build your skills in the high-demand field of data engineering and learn how you can deliver real business value by applying a core set of principles and ...', 'position': 9, 'sitelinks': [{'title': 'AI for Medicine Specialization', 'link': 'https://www.coursera.org/specializations/ai-for-medicine'}, {'title': 'AI and Climate Change', 'link': 'https://www.coursera.org/learn/ai-and-climate-change'}, {'title': 'Generative Adversarial...', 'link': 'https://www.coursera.org/specializations/generative-adversarial-networks-gans'}]}, {'title': 'Generative AI for Everyone - DeepLearning.AI', 'link': 'https://www.deeplearning.ai/courses/generative-ai-for-everyone/', 'snippet': 'Instructed by AI pioneer Andrew Ng, Generative AI for Everyone offers his unique perspective on empowering you and your work with generative AI.', 'position': 10}], 'peopleAlsoAsk': [{'question': 'Does Andrew Ng have a PhD?', 'snippet': 'In 2002, he received his Doctor of Philosophy (Ph. D.) in Computer Science from the University of California, Berkeley, under the supervision of Michael I. Jordan.', 'title': 'Andrew Ng - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Andrew_Ng'}, {'question': 'What are the three 3 key elements for AI?', 'snippet': 'So, while AI investments are predicted to top $200 billion by 2025, companies want assurances that their initiatives will bear fruit. This eBook details how democratization, operationalization, and trust— the three keys to effective adoption—promote successful outcomes.', 'title': 'The 3 Keys to Successful AI Outcomes - AWS', 'link': 'https://aws.amazon.com/resources/global-ln-gc-400-three-keys-ebook-learn/'}, {'question': 'Who is the CEO of deep learning company?', 'snippet': 'A globally recognized leader in AI, Dr. Andrew Ng leads AI Fund as the Managing General Partner. Additionally, he is the Founder and CEO of Landing AI, founder of DeepLearning.AI, chairman and co-founder of Coursera, and an adjunct professor at Stanford University.', 'title': 'Andrew Ng - AI FUND', 'link': 'https://aifund.ai/team-member/andrew-ng/'}, {'question': 'Who is the CEO of Landing AI?', 'snippet': 'Andrew Ng, CEO and Founder, Landing AI | CXOTalk.', 'title': 'Andrew Ng, CEO and Founder, Landing AI | CXOTalk', 'link': 'https://www.cxotalk.com/bio/andrew-ng-ceo-founder-landing-ai'}], 'relatedSearches': [{'query': 'Meta AI'}, {'query': 'Deeplearning ai business development key personnel review'}, {'query': 'Deeplearning ai business development key personnel free'}, {'query': 'Deeplearning ai business development key personnel certification'}, {'query': 'deeplearning.ai login'}, {'query': 'deeplearning.ai courses'}, {'query': 'deeplearning.ai courses free'}, {'query': 'deeplearning.ai prompt engineering'}, {'query': 'deeplearning.ai coursera'}], 'credits': 1}\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:01][🤖 LLM CALL STARTED]: 2025-03-11 12:57:01.111135\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:13][✅ LLM CALL COMPLETED]: 2025-03-11 12:57:13.631136\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:13][🤖 TOOL USAGE STARTED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:57:13.632655\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:14][✅ TOOL USAGE FINISHED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:57:14.308248\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSales Representative\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The search results confirm Andrew Ng as the founder.  More detailed information about specific key personnel beyond Andrew Ng and recent business developments requires further investigation.  Accessing their website directly might provide more information.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"DeepLearningAI about us\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'DeepLearningAI about us', 'type': 'search', 'num': 10, 'engine': 'google'}, 'knowledgeGraph': {'title': 'DeepLearning.AI', 'type': 'Corporate office in Palo Alto, California', 'website': 'https://www.deeplearning.ai/', 'imageUrl': 'https://streetviewpixels-pa.googleapis.com/v1/thumbnail?panoid=liL0KsV4k-lWksfl5g5wmQ&cb_client=search.gws-prod.gps&yaw=136.5963&pitch=0&thumbfov=100&w=240&h=360', 'description': '', 'descriptionSource': '', 'descriptionLink': '', 'attributes': {'Address': '195 Page Mill Rd #115, Palo Alto, CA 94306'}}, 'organic': [{'title': 'About - DeepLearning.AI', 'link': 'https://www.deeplearning.ai/about/', 'snippet': 'DeepLearning.AI is an education technology company that is empowering the global workforce to build an AI-powered future through world-class education.', 'position': 1}, {'title': 'DeepLearning.AI: Start or Advance Your Career in AI', 'link': 'https://www.deeplearning.ai/', 'snippet': 'Join over 7 million people learning how to use and build AI. AI Courses and Specializations. Build a foundation of machine learning and AI skills.', 'position': 2, 'sitelinks': [{'title': 'About', 'link': 'https://www.deeplearning.ai/about/'}, {'title': 'Careers', 'link': 'https://www.deeplearning.ai/careers/'}, {'title': 'Courses', 'link': 'https://www.deeplearning.ai/courses/'}, {'title': 'DeepLearning.AI', 'link': 'https://community.deeplearning.ai/'}]}, {'title': 'About The DeepLearning.AI Community', 'link': 'https://www.deeplearning.ai/community/', 'snippet': 'The DeepLearning.AI community is dedicated to providing the most educational resource of the AI industry.', 'position': 3, 'sitelinks': [{'title': 'DeepLearning.AI', 'link': 'https://community.deeplearning.ai/'}, {'title': 'Events', 'link': 'https://www.deeplearning.ai/events/'}, {'title': 'Background', 'link': 'https://www.deeplearning.ai/forum/community-programs/'}]}, {'title': 'DeepLearning.AI - LinkedIn', 'link': 'https://www.linkedin.com/company/deeplearningai', 'snippet': 'DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.', 'position': 4}, {'title': 'Deeplearning.ai - Crunchbase Company Profile & Funding', 'link': 'https://www.crunchbase.com/organization/deeplearning-ai', 'snippet': 'Deeplearning.ai is company that explores the frontier of AI. The company is founded by Andrew Ng, the former Chief Scientist of Baidu.', 'position': 5}, {'title': 'Deeplearning AI - American Council on Education', 'link': 'https://www.acenet.edu/National-Guide/Pages/Organization.aspx?oid=c823cbba-25f7-ec11-bb3d-0022480baa32', 'snippet': 'DeepLearning.Al empowers a global community of learners to shape the future of Artificial Intelligence (AlI) and achieve their goals through world-class ...', 'position': 6}, {'title': 'Andrew Ng - Founder - DeepLearning.AI - LinkedIn', 'link': 'https://www.linkedin.com/in/andrewyng', 'snippet': 'DeepLearning.AI provides technical training on Generative AI, Machine Learning, Deep Learning, and other topics. We also offer a widely read newsletter, ...', 'position': 7}, {'title': 'DeepLearning.AI Online Courses - Coursera', 'link': 'https://www.coursera.org/partners/deeplearning-ai', 'snippet': \"DeepLearning.AI is an education technology company that develops a global community of AI talent. DeepLearning.AI's expert-led educational experiences provide ...\", 'position': 8, 'sitelinks': [{'title': 'AI for Medicine Specialization', 'link': 'https://www.coursera.org/specializations/ai-for-medicine'}, {'title': 'AI and Climate Change', 'link': 'https://www.coursera.org/learn/ai-and-climate-change'}, {'title': 'Generative Adversarial...', 'link': 'https://www.coursera.org/specializations/generative-adversarial-networks-gans'}]}, {'title': 'About The DeepLearning.AI Community Programs', 'link': 'https://www.deeplearning.ai/forum/community-programs/', 'snippet': 'The DeepLearning.AI community forum is a diverse group of people from all over the world who are interested in learning all things AI.', 'position': 9}], 'peopleAlsoAsk': [{'question': 'What is DeepLearning.AI about?', 'snippet': 'Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, to simulate the complex decision-making power of the human brain. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today.', 'title': 'What Is Deep Learning? | IBM', 'link': 'https://www.ibm.com/think/topics/deep-learning'}, {'question': 'Does Andrew Ng have a PhD?', 'snippet': 'In 2002, he received his Doctor of Philosophy (Ph. D.) in Computer Science from the University of California, Berkeley, under the supervision of Michael I. Jordan.', 'title': 'Andrew Ng - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Andrew_Ng'}, {'question': 'Is DeepLearning.AI part of Coursera?', 'snippet': 'Deep learning is not part of Coursera Plus Subscription.', 'title': 'Deep learning is not part of Coursera Plus Subscription', 'link': 'https://www.coursera.support/s/question/0D51U00003BlXViSAN/deep-learning-is-not-part-of-coursera-plus-subscription?language=en_US'}, {'question': 'Does DeepLearning.AI give certificates?', 'snippet': 'TensorFlow is one of the most in-demand and popular open-source deep learning frameworks available today. The DeepLearning.AI TensorFlow Developer Professional Certificate program teaches you applied machine learning skills with TensorFlow so you can build and train powerful models.', 'title': 'DeepLearning.AI TensorFlow Developer Professional Certificate', 'link': 'https://www.coursera.org/professional-certificates/tensorflow-in-practice'}], 'relatedSearches': [{'query': 'Meta AI'}, {'query': 'Deeplearning AI Founder'}, {'query': 'Deeplearning ai about us free'}, {'query': 'Deeplearning AI login'}, {'query': 'Deeplearning AI CEO'}, {'query': 'Deeplearning ai about us questions'}, {'query': 'Deeplearning ai about us pdf'}, {'query': 'Deeplearning AI courses'}, {'query': 'Deeplearning AI community'}], 'credits': 1}\n",
            "\n",
            "\n",
            "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
            "\n",
            "Tool Name: List files in directory\n",
            "Tool Arguments: {}\n",
            "Tool Description: A tool that can be used to list ./instructions's content.\n",
            "Tool Name: Read a file's content\n",
            "Tool Arguments: {'file_path': {'description': 'Mandatory file full path to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that reads the content of a file. To use this tool, provide a 'file_path' parameter with the path to the file you want to read.\n",
            "Tool Name: Search the internet with Serper\n",
            "Tool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\n",
            "Tool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\n",
            "\n",
            "IMPORTANT: Use the following format in your response:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, only one name of [List files in directory, Read a file's content, Search the internet with Serper], just the name, exactly as it's written.\n",
            "Action Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\n",
            "Observation: the result of the action\n",
            "```\n",
            "\n",
            "Once all necessary information is gathered, return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "```\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:14][🤖 LLM CALL STARTED]: 2025-03-11 12:57:14.308589\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:20][✅ LLM CALL COMPLETED]: 2025-03-11 12:57:20.347629\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSales Representative\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "**DeepLearningAI Comprehensive Report**\n",
            "\n",
            "**Company Background:**\n",
            "\n",
            "DeepLearning.AI is an education technology company founded by Andrew Ng, a prominent figure in the AI field.  Its mission is to provide world-class AI education to empower the global workforce and build an AI-powered future.  The company offers a wide range of courses and specializations on various aspects of AI, including machine learning, deep learning, and generative AI.  These courses are accessible through platforms like Coursera and their own learning platform. DeepLearning.AI boasts a large global community of learners.\n",
            "\n",
            "\n",
            "**Key Personnel:**\n",
            "\n",
            "* **Andrew Ng:** Founder and a key driving force behind DeepLearning.AI's vision and educational content.  His extensive experience and reputation in AI significantly contribute to the company's credibility and reach.  Further details regarding other key personnel require additional research beyond the scope of readily available information.  LinkedIn and company websites may provide a more complete list of executive team members.\n",
            "\n",
            "**Recent Milestones:**\n",
            "\n",
            "* The specific recent milestones of DeepLearningAI are not clearly identified in the readily available information.  More detailed information regarding partnerships, new course launches, and funding updates would require digging into news articles and press releases specific to DeepLearningAI.\n",
            "\n",
            "**Identified Needs:**\n",
            "\n",
            "Given DeepLearning.AI's focus on education and its massive online presence, potential needs could include:\n",
            "\n",
            "* **Enhanced Learning Platform:**  Improvements to the user experience, course management systems, and features for learner engagement could be valuable.\n",
            "* **Scalability and Performance:**  As the number of students grows, maintaining platform stability, responsiveness, and efficient content delivery becomes crucial.\n",
            "* **Personalized Learning Experiences:**  Tools that personalize learning paths and content based on individual student progress and preferences could significantly enhance the learning experience.\n",
            "* **Advanced Analytics:**  More sophisticated analytics to track student performance, identify areas for improvement in the curriculum, and optimize course delivery.\n",
            "* **Community Engagement Tools:**  Better tools to foster collaboration and interaction among students could increase engagement and knowledge sharing.\n",
            "\n",
            "**Potential Areas Where CrewAI Solutions Can Provide Value:**\n",
            "\n",
            "CrewAI's multi-AI agent system solutions could directly address some of DeepLearning.AI's potential needs:\n",
            "\n",
            "* **Automated Content Creation and Curation:** AI agents could assist in generating educational materials, quizzes, and practice exercises, reducing the workload on the instructional team.\n",
            "* **Personalized Learning Paths:** AI-powered systems could dynamically adjust learning paths based on student performance, ensuring a tailored and effective learning experience.\n",
            "* **Improved Learner Support:** AI chatbots could answer frequently asked questions, provide immediate assistance to students, and free up human instructors to focus on more complex tasks.\n",
            "* **Advanced Analytics and Insights:** CrewAI's analytics capabilities can provide valuable data on student behavior and performance, aiding in curriculum optimization and enhancing the learning experience.\n",
            "\n",
            "**Suggested Personalized Engagement Strategies:**\n",
            "\n",
            "1. **Targeted Outreach:** Identify specific decision-makers within DeepLearning.AI (beyond Andrew Ng) through LinkedIn and other professional networks.  Focus on individuals responsible for technology, educational platform development, or instructional design.\n",
            "\n",
            "2. **Value-Based Messaging:** Highlight how CrewAI's solutions directly address the identified needs, emphasizing increased efficiency, scalability, and enhanced learner outcomes.  Use case studies and data to demonstrate the value proposition.\n",
            "\n",
            "3. **Personalized Demonstrations:**  Offer tailored demos of CrewAI's capabilities tailored to the specific challenges and opportunities faced by DeepLearning.AI.\n",
            "\n",
            "4. **Collaborative Approach:** Emphasize a partnership approach, focusing on joint development and ongoing collaboration to create optimal solutions.\n",
            "\n",
            "5. **Long-Term Vision:**  Frame the engagement as a strategic partnership aimed at creating a long-term solution, showcasing the potential for growth and innovation together.\n",
            "\n",
            "\n",
            "This report is based on publicly available information.  Further research into DeepLearningAI's recent business activities, funding rounds, and more detailed organizational structure may be necessary for a more comprehensive analysis.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:20][✅ AGENT 'SALES REPRESENTATIVE' COMPLETED TASK]: 2025-03-11 12:57:20.348937\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:20][✅ TASK COMPLETED: CONDUCT AN IN-DEPTH ANALYSIS OF DEEPLEARNINGAI, A COMPANY IN THE ONLINE LEARNING PLATFORM SECTOR THAT RECENTLY SHOWED INTEREST IN OUR SOLUTIONS. UTILIZE ALL AVAILABLE DATA SOURCES TO COMPILE A DETAILED PROFILE, FOCUSING ON KEY DECISION-MAKERS, RECENT BUSINESS DEVELOPMENTS, AND POTENTIAL NEEDS THAT ALIGN WITH OUR OFFERINGS. THIS TASK IS CRUCIAL FOR TAILORING OUR ENGAGEMENT STRATEGY EFFECTIVELY.\n",
            "DON'T MAKE ASSUMPTIONS AND ONLY USE INFORMATION YOU ABSOLUTELY SURE ABOUT.]: 2025-03-11 12:57:20.349224\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:20][📋 TASK STARTED: USING THE INSIGHTS GATHERED FROM THE LEAD PROFILING REPORT ON DEEPLEARNINGAI, CRAFT A PERSONALIZED OUTREACH CAMPAIGN AIMED AT ANDREW NG, THE CEO OF DEEPLEARNINGAI. THE CAMPAIGN SHOULD ADDRESS THEIR RECENT PRODUCT LAUNCH AND HOW OUR SOLUTIONS CAN SUPPORT THEIR GOALS. YOUR COMMUNICATION MUST RESONATE WITH DEEPLEARNINGAI'S COMPANY CULTURE AND VALUES, DEMONSTRATING A DEEP UNDERSTANDING OF THEIR BUSINESS AND NEEDS.\n",
            "DON'T MAKE ASSUMPTIONS AND ONLY USE INFORMATION YOU ABSOLUTELY SURE ABOUT.]: 2025-03-11 12:57:20.368956\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:20][🤖 AGENT 'LEAD SALES REPRESENTATIVE' STARTED TASK]: 2025-03-11 12:57:20.371181\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLead Sales Representative\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mUsing the insights gathered from the lead profiling report on DeepLearningAI, craft a personalized outreach campaign aimed at Andrew Ng, the CEO of DeepLearningAI. The campaign should address their recent product launch and how our solutions can support their goals. Your communication must resonate with DeepLearningAI's company culture and values, demonstrating a deep understanding of their business and needs.\n",
            "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:20][🤖 LLM CALL STARTED]: 2025-03-11 12:57:20.371431\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:25][✅ LLM CALL COMPLETED]: 2025-03-11 12:57:25.881326\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:25][🤖 TOOL USAGE STARTED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:57:25.881731\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:26][✅ TOOL USAGE FINISHED: 'SEARCH THE INTERNET WITH SERPER']: 2025-03-11 12:57:26.601682\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLead Sales Representative\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"DeepLearningAI recent news press releases\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'DeepLearningAI recent news press releases', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'The Batch | DeepLearning.AI | AI News & Insights', 'link': 'https://www.deeplearning.ai/the-batch/', 'snippet': 'Grok 3 Scales Up, Mobile Apps Generated To Order, Musk Moves On OpenAI, Officials Reverse Course on AI Regulation. The Batch AI News and Insights: Last month, ...', 'position': 1, 'sitelinks': [{'title': 'About', 'link': 'https://www.deeplearning.ai/the-batch/about/'}, {'title': 'AI Careers', 'link': 'https://www.deeplearning.ai/the-batch/tag/ai-careers/'}, {'title': 'Reinforcement Learning Heats...', 'link': 'https://www.deeplearning.ai/the-batch/issue-286/'}, {'title': 'O3-mini Puts Reasoning in...', 'link': 'https://www.deeplearning.ai/the-batch/issue-287/'}]}, {'title': 'Search | The Batch | AI News & Insights - DeepLearning.AI', 'link': 'https://www.deeplearning.ai/search/', 'snippet': \"Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today's\", 'position': 2}, {'title': 'News and Announcements - DeepLearning.AI', 'link': 'https://community.deeplearning.ai/c/news-and-announcements/24', 'snippet': 'News and Announcements ; Mistral releases Arabic-focused language model for Middle East market · ai-discussions , data-points. 0 ; ✨ New course! Enroll in ...', 'position': 3}, {'title': 'DeepLearning.AI: Start or Advance Your Career in AI', 'link': 'https://www.deeplearning.ai/', 'snippet': 'AI is the new electricity. You are the spark. Get the latest AI news, courses, events, and insights from Andrew Ng and other AI leaders.', 'position': 4, 'sitelinks': [{'title': 'The Batch', 'link': 'https://www.deeplearning.ai/the-batch/'}, {'title': 'Careers', 'link': 'https://www.deeplearning.ai/careers/'}, {'title': 'Short Courses', 'link': 'https://www.deeplearning.ai/courses/?courses_date_desc%5BrefinementList%5D%5Bcourse_type%5D%5B0%5D=Short%20Courses'}, {'title': 'Courses', 'link': 'https://www.deeplearning.ai/courses/'}]}, {'title': 'Reinforcement Learning Heats Up, White House Orders Muscular AI ...', 'link': 'https://www.deeplearning.ai/the-batch/issue-286/', 'snippet': 'The buzz over DeepSeek this week crystallized, for many people, a few important trends that have been happening in plain sight.', 'position': 5}, {'title': 'deeplearning.ai News, Stories and Latest Updates 2025', 'link': 'https://analyticsindiamag.com/news/deeplearning-ai/', 'snippet': \"DeepLearning.AI Announces Short Course on Anthropic Claude's Computer Use · Andrew Ng Releases New Short Course on Building Safe & Reliable AI · Andrew Ng ...\", 'position': 6}, {'title': 'DeepLearning.AI (@DeepLearningAI) / X', 'link': 'https://x.com/deeplearningai?lang=en', 'snippet': 'We are an education technology company with the mission to grow and connect the global AI community.', 'position': 7}, {'title': 'Climate Change | The Batch | AI News & Insights', 'link': 'https://www.deeplearning.ai/the-batch/tag/climate-change/', 'snippet': 'A roadmap explores how AI can detect and mitigate greenhouse gases. How can AI help to fight climate change? A new report evaluates progress so far.', 'position': 8}, {'title': 'DeepLearningAI Flash News List | Blockchain.News', 'link': 'https://blockchain.news/flashnews/DeepLearningAI', 'snippet': 'List of Flash News about DeepLearningAI ; 2025-03-04 01:51. DeepLearning.AI Announces AI Dev 25 Event Recording Release. According to DeepLearning.AI, the AI Dev ...', 'position': 9}, {'title': 'Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, and ...', 'link': 'https://www.deeplearning.ai/the-batch/issue-281/', 'snippet': 'AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications.', 'position': 10}], 'relatedSearches': [{'query': 'Deeplearning ai recent news press releases pdf'}, {'query': 'Deeplearning AI login'}, {'query': 'deeplearning.ai courses'}, {'query': 'deeplearning.ai courses free'}, {'query': 'LLM deeplearning AI'}, {'query': 'deeplearning.ai rag'}, {'query': 'Deeplearning AI agents'}, {'query': 'deeplearning.ai certificate value'}], 'credits': 1}\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:26][🤖 LLM CALL STARTED]: 2025-03-11 12:57:26.602578\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:32][✅ LLM CALL COMPLETED]: 2025-03-11 12:57:32.466764\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:32][🤖 TOOL USAGE STARTED: 'SENTIMENT ANALYSIS TOOL']: 2025-03-11 12:57:32.468080\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:32][✅ TOOL USAGE FINISHED: 'SENTIMENT ANALYSIS TOOL']: 2025-03-11 12:57:32.471649\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLead Sales Representative\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSentiment Analysis Tool\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"text\\\": \\\"I am excited to connect with you and discuss how CrewAI can support DeepLearningAI's mission of providing world-class AI education.  I noticed your recent newsletter, 'The Batch,' highlighted practical applications of AI, and I believe CrewAI's solutions can significantly enhance the learning experience for your students.  Our AI-powered tools can automate content creation, personalize learning paths, provide improved learner support, and deliver advanced analytics, all of which align perfectly with DeepLearningAI's commitment to excellence and innovation.\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "positive\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:32][🤖 LLM CALL STARTED]: 2025-03-11 12:57:32.472069\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:36][✅ LLM CALL COMPLETED]: 2025-03-11 12:57:36.872835\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLead Sales Representative\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "**Email 1: Initial Outreach**\n",
            "\n",
            "Subject: Enhancing DeepLearning.AI's Impact with AI-Powered Solutions\n",
            "\n",
            "Dear Mr. Ng,\n",
            "\n",
            "I hope this email finds you well.\n",
            "\n",
            "My name is [Your Name], Lead Sales Representative at CrewAI.  I've been following DeepLearning.AI's work with great interest, particularly your recent newsletters highlighting the practical applications of AI in various fields.  At CrewAI, we develop multi-AI agent systems designed to streamline educational processes and enhance learner outcomes.\n",
            "\n",
            "I noticed your commitment to providing world-class AI education, and I believe CrewAI's solutions could significantly amplify your impact.  Our platform offers automated content creation, personalized learning paths, improved learner support through AI chatbots, and advanced analytics for curriculum optimization.  These features would allow DeepLearning.AI to scale its operations while maintaining the highest standards of educational excellence.\n",
            "\n",
            "Would you be open to a brief call next week to discuss how CrewAI can help DeepLearning.AI achieve its goals?\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "Lead Sales Representative, CrewAI\n",
            "\n",
            "\n",
            "**Email 2: Follow-up**\n",
            "\n",
            "Subject: Following Up: CrewAI and DeepLearning.AI\n",
            "\n",
            "Dear Mr. Ng,\n",
            "\n",
            "I hope this email finds you well.\n",
            "\n",
            "I'm following up on my previous email regarding CrewAI's AI-powered solutions for educational platforms.  I understand your time is valuable, so I've prepared a brief overview of how CrewAI can specifically address challenges related to content creation, personalized learning, and student support within DeepLearning.AI's ecosystem.\n",
            "\n",
            "I've attached this overview for your review.  Are there any specific areas you'd like to discuss further, or would you be available for a quick 15-minute call to explore this in more detail?\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "Lead Sales Representative, CrewAI\n",
            "\n",
            "\n",
            "**Email 3: Post-Demo**\n",
            "\n",
            "Subject: Next Steps: CrewAI and DeepLearning.AI Partnership\n",
            "\n",
            "Dear Mr. Ng,\n",
            "\n",
            "Thank you for taking the time to review CrewAI's capabilities during our recent demo.  I hope you found it informative and saw the potential for our AI agents to significantly enhance DeepLearning.AI's platform and educational offerings.\n",
            "\n",
            "Based on our conversation, I've put together a proposal outlining a tailored approach to integrate CrewAI's solutions within your existing infrastructure.  This proposal details the potential impact on key metrics such as student engagement, content creation efficiency, and overall learning outcomes.\n",
            "\n",
            "I've attached the proposal for your consideration. I'm available to answer any further questions and discuss next steps at your convenience.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "Lead Sales Representative, CrewAI\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:36][✅ AGENT 'LEAD SALES REPRESENTATIVE' COMPLETED TASK]: 2025-03-11 12:57:36.874370\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:36][✅ TASK COMPLETED: USING THE INSIGHTS GATHERED FROM THE LEAD PROFILING REPORT ON DEEPLEARNINGAI, CRAFT A PERSONALIZED OUTREACH CAMPAIGN AIMED AT ANDREW NG, THE CEO OF DEEPLEARNINGAI. THE CAMPAIGN SHOULD ADDRESS THEIR RECENT PRODUCT LAUNCH AND HOW OUR SOLUTIONS CAN SUPPORT THEIR GOALS. YOUR COMMUNICATION MUST RESONATE WITH DEEPLEARNINGAI'S COMPANY CULTURE AND VALUES, DEMONSTRATING A DEEP UNDERSTANDING OF THEIR BUSINESS AND NEEDS.\n",
            "DON'T MAKE ASSUMPTIONS AND ONLY USE INFORMATION YOU ABSOLUTELY SURE ABOUT.]: 2025-03-11 12:57:36.874607\u001b[00m\n",
            "\u001b[1m\u001b[94m \n",
            "[2025-03-11 12:57:36][✅ CREW 'CREW' COMPLETED, 92697830-FA5C-4BBF-A230-8261F42C8F0A]: 2025-03-11 12:57:36.889902\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(str(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "PWs8yUdwQbM1",
        "outputId": "10088f9a-1d45-402e-c2ab-a706edd57da1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Email 1: Initial Outreach**\n\nSubject: Enhancing DeepLearning.AI's Impact with AI-Powered Solutions\n\nDear Mr. Ng,\n\nI hope this email finds you well.\n\nMy name is [Your Name], Lead Sales Representative at CrewAI.  I've been following DeepLearning.AI's work with great interest, particularly your recent newsletters highlighting the practical applications of AI in various fields.  At CrewAI, we develop multi-AI agent systems designed to streamline educational processes and enhance learner outcomes.\n\nI noticed your commitment to providing world-class AI education, and I believe CrewAI's solutions could significantly amplify your impact.  Our platform offers automated content creation, personalized learning paths, improved learner support through AI chatbots, and advanced analytics for curriculum optimization.  These features would allow DeepLearning.AI to scale its operations while maintaining the highest standards of educational excellence.\n\nWould you be open to a brief call next week to discuss how CrewAI can help DeepLearning.AI achieve its goals?\n\nSincerely,\n\n[Your Name]\nLead Sales Representative, CrewAI\n\n\n**Email 2: Follow-up**\n\nSubject: Following Up: CrewAI and DeepLearning.AI\n\nDear Mr. Ng,\n\nI hope this email finds you well.\n\nI'm following up on my previous email regarding CrewAI's AI-powered solutions for educational platforms.  I understand your time is valuable, so I've prepared a brief overview of how CrewAI can specifically address challenges related to content creation, personalized learning, and student support within DeepLearning.AI's ecosystem.\n\nI've attached this overview for your review.  Are there any specific areas you'd like to discuss further, or would you be available for a quick 15-minute call to explore this in more detail?\n\nSincerely,\n\n[Your Name]\nLead Sales Representative, CrewAI\n\n\n**Email 3: Post-Demo**\n\nSubject: Next Steps: CrewAI and DeepLearning.AI Partnership\n\nDear Mr. Ng,\n\nThank you for taking the time to review CrewAI's capabilities during our recent demo.  I hope you found it informative and saw the potential for our AI agents to significantly enhance DeepLearning.AI's platform and educational offerings.\n\nBased on our conversation, I've put together a proposal outlining a tailored approach to integrate CrewAI's solutions within your existing infrastructure.  This proposal details the potential impact on key metrics such as student engagement, content creation efficiency, and overall learning outcomes.\n\nI've attached the proposal for your consideration. I'm available to answer any further questions and discuss next steps at your convenience.\n\nSincerely,\n\n[Your Name]\nLead Sales Representative, CrewAI"
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znEJAZfZQbIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-jJzK0oQbFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jrNpBR_VQbDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y03UdWbKQbAo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}